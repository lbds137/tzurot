# Testing Guide

**Last Updated:** 2026-01-03
**Status:** Foundation complete, expanding coverage

> **Purpose:** Guidelines and patterns for writing tests in Tzurot v3

---

## Table of Contents

1. [Philosophy](#philosophy)
2. [Test Infrastructure](#test-infrastructure)
3. [Writing Tests](#writing-tests)
4. [Mocking Dependencies](#mocking-dependencies)
5. [Running Tests](#running-tests)
6. [Memory Optimization](#memory-optimization)
7. [Examples](#examples)
8. [Common Patterns](#common-patterns)
9. [Troubleshooting](#troubleshooting)

---

## Philosophy

### Core Principles

**Test Behavior, Not Implementation**

- Focus on WHAT code does, not HOW it does it
- Test the public API only
- Don't test private methods or internal state
- If you need to test implementation details, extract them to a separate tested module

**Keep Tests Simple and Readable**

- Clear, descriptive test names
- One assertion per concept
- Arrange-Act-Assert pattern
- Comment WHY when the behavior is non-obvious

**Mock External Dependencies**

- Database calls ‚Üí Mock PersonalityService, UserService, etc.
- API calls ‚Üí Mock AI providers, Discord API
- Time-based code ‚Üí Use fake timers
- File system ‚Üí Mock file operations
- Never hit real external services in unit tests

**Fast and Isolated**

- Tests should run in milliseconds
- Each test is independent
- No shared state between tests
- Use `beforeEach` to reset mocks

---

## Test Infrastructure

### Directory Structure

```
services/bot-client/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ personalityMentionParser.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ personalityMentionParser.test.ts    ‚Üê Tests next to code
‚îÇ   ‚îú‚îÄ‚îÄ handlers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MessageHandler.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ MessageHandler.test.ts
‚îÇ   ‚îî‚îÄ‚îÄ test/
‚îÇ       ‚îú‚îÄ‚îÄ setup.ts                             ‚Üê Global test setup
‚îÇ       ‚îî‚îÄ‚îÄ mocks/
‚îÇ           ‚îú‚îÄ‚îÄ PersonalityService.mock.ts      ‚Üê Reusable mocks
‚îÇ           ‚îú‚îÄ‚îÄ UserService.mock.ts
‚îÇ           ‚îî‚îÄ‚îÄ Discord.mock.ts
‚îú‚îÄ‚îÄ vitest.config.ts                             ‚Üê Service-specific config
‚îî‚îÄ‚îÄ package.json
```

### Configuration Files

**Root `/vitest.config.ts`:** Shared configuration for all services

- Fake timers enabled by default
- Coverage settings
- Test environment (Node.js)

**Service `/services/*/vitest.config.ts`:** Extends root config

- Service-specific test patterns
- Setup files
- Path aliases

### Available Tools

- **Vitest v4.0.3** - Test framework
- **Built-in mocking** - `vi.fn()`, `vi.mock()`
- **Fake timers** - `vi.useFakeTimers()`, `vi.advanceTimersByTime()`
- **Assertions** - `expect()` with matchers

---

## Writing Tests

### Test File Naming

Tzurot uses a **hybrid naming strategy** combining suffixes and directories:

**Colocated Tests (suffixes distinguish type):**

- **Unit Tests:** `*.test.ts` - All dependencies mocked
- **Component Tests:** `*.component.test.ts` - Real in-memory DB (PGlite), mocked external services

**Integration Tests (directory-based):**

- **Integration Tests:** `tests/integration/*.test.ts` - Real DB, Redis, external services

**Examples:**

```
services/ai-worker/src/
‚îú‚îÄ‚îÄ jobs/
‚îÇ   ‚îú‚îÄ‚îÄ AIJobProcessor.ts
‚îÇ   ‚îú‚îÄ‚îÄ AIJobProcessor.test.ts           ‚Üê Unit test (all mocked)
‚îÇ   ‚îî‚îÄ‚îÄ AIJobProcessor.component.test.ts ‚Üê Component test (real PGlite)
‚îî‚îÄ‚îÄ services/
    ‚îú‚îÄ‚îÄ PersonalityService.ts
    ‚îî‚îÄ‚îÄ PersonalityService.test.ts       ‚Üê Unit test (all mocked)

tests/integration/
‚îú‚îÄ‚îÄ AIRoutes.test.ts                     ‚Üê Integration test (real DB+Redis)
‚îî‚îÄ‚îÄ PersonalityService.test.ts           ‚Üê Integration test (real DB+Redis)
```

**Why This Matters:**

- File name immediately signals what's mocked vs real
- Enables CI/CD optimization (run unit ‚Üí component ‚Üí integration)
- Reduces cognitive load when reading tests

### Test Structure

```typescript
import { describe, it, expect, beforeEach } from 'vitest';
import { functionToTest } from './module.js';
import { createMockDependency } from '../test/mocks/Dependency.mock.js';

describe('Module Name', () => {
  let mockDependency: DependencyType;

  beforeEach(() => {
    // Fresh mocks before each test
    mockDependency = createMockDependency(/* config */);
  });

  describe('Feature Group', () => {
    it('should do X when Y happens', async () => {
      // Arrange: Set up test data
      const input = 'test input';

      // Act: Execute the code under test
      const result = await functionToTest(input, mockDependency);

      // Assert: Verify the behavior
      expect(result).toBe('expected output');
    });

    it('should handle edge case Z', async () => {
      const result = await functionToTest('', mockDependency);
      expect(result).toBeNull();
    });
  });
});
```

### Test Naming Conventions

**Good:**

- ‚úÖ `should find single-word personality mention`
- ‚úÖ `should return null when no personality is mentioned`
- ‚úÖ `should prioritize multi-word over single-word personalities`

**Bad:**

- ‚ùå `test1`
- ‚ùå `it works`
- ‚ùå `findPersonalityMention returns Lilith`

**Pattern:** `should [expected behavior] when [condition]`

### What to Test

**‚úÖ DO Test:**

- Public API functions
- Edge cases (empty strings, null, undefined)
- Error conditions
- Different input combinations
- Boundary conditions

**‚ùå DON'T Test:**

- Private methods
- Implementation details (regex patterns, loops)
- External library behavior
- Getters/setters with no logic

---

## Mocking Dependencies

### Creating Mock Services

**Pattern:** Factory function in `/test/mocks/`

```typescript
// src/test/mocks/PersonalityService.mock.ts
import { vi } from 'vitest';
import type { PersonalityService } from '@tzurot/common-types';

export function createMockPersonalityService(personalities: MockPersonality[]): PersonalityService {
  const personalityMap = new Map(personalities.map(p => [p.name.toLowerCase(), p]));

  return {
    loadPersonality: vi.fn(async (name: string) => {
      const personality = personalityMap.get(name.toLowerCase());
      return personality ? mockPersonalityObject(personality) : null;
    }),

    getAllPersonalities: vi.fn(async () => personalities as any[]),
  } as any;
}
```

**Usage in tests:**

```typescript
import { createMockPersonalityService } from '../test/mocks/PersonalityService.mock.js';

describe('My Feature', () => {
  let mockService: PersonalityService;

  beforeEach(() => {
    mockService = createMockPersonalityService([
      { name: 'Lilith', displayName: 'Lilith', systemPrompt: '...' },
      { name: 'Sarcastic', displayName: 'Sarcastic', systemPrompt: '...' },
    ]);
  });

  it('should use the mock service', async () => {
    const result = await myFunction(mockService);
    expect(result).toBeDefined();

    // Verify the mock was called
    expect(mockService.loadPersonality).toHaveBeenCalledWith('Lilith');
  });
});
```

### Verifying Mock Calls

```typescript
// Check if mock was called
expect(mockService.loadPersonality).toHaveBeenCalled();

// Check call count
expect(mockService.loadPersonality).toHaveBeenCalledTimes(2);

// Check arguments
expect(mockService.loadPersonality).toHaveBeenCalledWith('Lilith');

// Check call order
expect(mockService.loadPersonality).toHaveBeenNthCalledWith(1, 'First');
expect(mockService.loadPersonality).toHaveBeenNthCalledWith(2, 'Second');
```

### Using Fake Timers

```typescript
import { vi, beforeEach, afterEach } from 'vitest';

describe('Timer-based code', () => {
  beforeEach(() => {
    vi.useFakeTimers();
  });

  afterEach(() => {
    vi.restoreAllMocks();
  });

  it('should do something after delay', async () => {
    const callback = vi.fn();

    setTimeout(callback, 1000);

    // Fast-forward time
    vi.advanceTimersByTime(1000);

    expect(callback).toHaveBeenCalled();
  });
});
```

### Testing Promise Rejections with Fake Timers

**‚ö†Ô∏è Common Issue:** When testing code that rejects promises after timer delays (e.g., retry logic, timeouts), you may see `PromiseRejectionHandledWarning` even though tests pass.

**The Problem:** A race condition between timer advancement and handler attachment:

1. Create promise (no handler yet)
2. Advance timers ‚Üí rejection occurs
3. Promise rejected with NO handler ‚Üí warning
4. Handler attached too late

**‚úÖ Solution:** Attach assertion handlers BEFORE advancing timers

```typescript
// ‚úÖ CORRECT: Attach handler before advancing timers
it('should throw RetryError after all attempts fail', async () => {
  const fn = vi.fn().mockRejectedValue(new Error('Fail'));

  // 1. Create the promise
  const promise = withRetry(fn, { maxAttempts: 3, initialDelayMs: 100 });

  // 2. Attach handler BEFORE advancing timers
  const assertionPromise = expect(promise).rejects.toThrow(RetryError);

  // 3. NOW advance timers to trigger rejection
  await vi.runAllTimersAsync();

  // 4. Await the assertion
  await assertionPromise;

  // 5. Additional assertions
  expect(fn).toHaveBeenCalledTimes(3);
});

// ‚ùå INCORRECT: Handler attached too late (causes warnings)
it('should throw error', async () => {
  const promise = withRetry(fn, { maxAttempts: 3 });

  await vi.runAllTimersAsync(); // ‚ùå Rejection happens here

  // ‚ùå Handler attached after rejection
  await expect(promise).rejects.toThrow(RetryError);
});
```

**Alternative Pattern** (when you need to inspect the error):

```typescript
it('should throw with specific error details', async () => {
  expect.assertions(2);

  const fn = vi.fn().mockRejectedValue(new Error('Fail'));

  try {
    const promise = withRetry(fn, { maxAttempts: 3 });
    await vi.runAllTimersAsync();
    await promise;
  } catch (e: any) {
    expect(e).toBeInstanceOf(RetryError);
    expect(e.attempts).toBe(3);
  }
});
```

**Why This Works:** The `expect().rejects` matcher attaches the promise handler immediately when called, preventing the "unhandled rejection" state.

**Reference:** Gemini AI collaboration, PR #206 (2025-11-02)

### Fake Timers and Async Code Interaction

**‚ö†Ô∏è Critical Issue:** When using `vi.useFakeTimers()` with async/await, the `await` keyword yields control to the test runner's event loop, which can cause pending timers to fire unexpectedly.

**The Problem:** Code with `setTimeout` for AbortController timeouts can fail even when mocks resolve immediately:

```typescript
// Code being tested
async function fetchWithTimeout(url) {
  const controller = new AbortController();
  const timeout = setTimeout(() => controller.abort(), 30000);

  try {
    const response = await fetch(url, { signal: controller.signal });
    clearTimeout(timeout);
    return response;
  } catch (error) {
    clearTimeout(timeout);
    throw error;
  }
}

// ‚ùå Test fails even though fetch mock resolves immediately
describe('with fake timers', () => {
  beforeEach(() => vi.useFakeTimers());

  it('should fetch successfully', async () => {
    global.fetch = vi.fn().mockResolvedValue({ ok: true });

    // The await gives fake timers a chance to run
    // The 30s timeout fires immediately, aborting the fetch!
    const result = await fetchWithTimeout('https://example.com');

    expect(result.ok).toBe(true); // ‚ùå Fails with AbortError
  });
});
```

**What Happens:**

1. `setTimeout` schedules the abort for 30,000ms (fake time)
2. `fetch` returns a resolved promise (mocked)
3. `await` yields control to the event loop
4. Vitest sees pending timer and runs it to prevent deadlock
5. `controller.abort()` fires before fetch promise completes
6. Test fails with `AbortError`

**‚úÖ Solution 1:** Advance timers by 0ms to flush promise microtasks without triggering macrotasks

```typescript
it('should fetch successfully', async () => {
  global.fetch = vi.fn().mockResolvedValue({ ok: true });

  // Call but don't await yet
  const promise = fetchWithTimeout('https://example.com');

  // Advance by 0ms to let promises resolve without firing timers
  await vi.advanceTimersByTimeAsync(0);

  // Now await the result
  const result = await promise;

  expect(result.ok).toBe(true); // ‚úì Passes
});
```

**‚úÖ Solution 2:** Use real timers for tests not focused on timeout logic

```typescript
it('should fetch successfully', async () => {
  // Temporarily disable fake timers for this test
  vi.useRealTimers();

  global.fetch = vi.fn().mockResolvedValue({ ok: true });
  const result = await fetchWithTimeout('https://example.com');

  expect(result.ok).toBe(true); // ‚úì Passes

  // Restore fake timers for other tests if needed
  vi.useFakeTimers();
});
```

**When to Use Each Solution:**

- **Solution 1:** When testing timeout logic is important
- **Solution 2:** When you only care about the happy path (recommended for simplicity)

**Testing the Timeout Path:** To verify timeout logic works, make the promise never resolve:

```typescript
it('should timeout and abort', async () => {
  // Mock that never resolves (simulates hang)
  global.fetch = vi.fn(() => new Promise(() => {}));

  const promise = fetchWithTimeout('https://example.com');

  // Advance past the timeout
  await vi.advanceTimersByTimeAsync(30000);

  await expect(promise).rejects.toThrow('AbortError');
});
```

**Key Insight:** `await` in tests with fake timers creates a checkpoint where Vitest can advance pending timers. Design tests accordingly.

**Reference:** Gemini AI collaboration during MultimodalProcessor test development (2025-11-15)

---

## Running Tests

### Commands

```bash
# Run all tests (from root)
pnpm test

# Run tests for specific service
cd services/bot-client
pnpm test

# Watch mode (re-run on file changes)
pnpm test --watch

# Coverage report
pnpm test --coverage

# Run specific test file
pnpm test personalityMentionParser.test.ts

# Run tests matching pattern
pnpm test --grep "Priority Rules"
```

### CI/CD Integration

Tests run automatically on:

- Pre-commit hooks (future)
- Pull request CI (future)
- Before deployments (future)

---

## Memory Optimization

When running the full test suite (5000+ tests), memory usage can spike significantly due to multiple Vitest processes and workers. This section documents strategies for reducing RAM consumption.

### Current Configuration

The base `vitest.config.ts` includes these memory-saving settings:

```typescript
// Vitest 4 top-level pool options (replaces poolOptions.threads)
pool: 'threads',
maxWorkers: 3,       // Limit workers (default uses all CPU cores)
minWorkers: 1,
mockReset: true,     // Clear mocks between tests
restoreMocks: true,  // Restore original implementations
```

### Available Commands

| Command | Memory Usage | Speed | Use Case |
|---------|-------------|-------|----------|
| `pnpm test` | Moderate | Fast | CI, machines with 16GB+ RAM |
| `pnpm test:low-mem` | Low | Slower | Development on limited RAM |

The `test:low-mem` command uses `--workspace-concurrency=1` to run one service at a time instead of all 4 in parallel.

### IDE Tips

- **Run full suite in external terminal** - The integrated terminal shares renderer memory with the IDE
- **Disable auto-watch for full suite** - Watch mode on 5000+ tests consumes significant resources
- **Run individual service tests during development** - `pnpm --filter @tzurot/bot-client test`

### Advanced Options (Not Currently Implemented)

If memory issues persist, consider these additional strategies:

#### 1. Vitest Workspaces (Single Process)

Instead of 4 separate Vitest processes, use a single root instance:

```typescript
// vitest.workspace.ts (in project root)
export default ['packages/*', 'services/*']
```

Then run `vitest run` instead of pnpm filter. One process manages all tests, sharing the worker pool efficiently.

#### 2. Node.js Memory Flags

Set a hard memory limit to crash gracefully instead of freezing:

```bash
NODE_OPTIONS="--max-old-space-size=4096" pnpm test
```

Or add `--logHeapUsage` to Vitest to identify memory-heavy test files.

#### 3. Forks Pool (Better Isolation)

Switch from threads to forks for cleaner memory slate per test file:

```typescript
pool: 'forks',
poolOptions: {
  forks: {
    maxForks: 2,
    minForks: 1,
  },
},
```

Trade-off: Slower startup per file but better memory isolation.

#### 4. Heap Usage Logging

Identify which test files consume the most memory:

```typescript
test: {
  logHeapUsage: true,
}
```

### Reference

These recommendations were developed with MCP council consultation (Gemini) analyzing:
- 8-core CPU with 14GB RAM (Steam Deck)
- 4 pnpm workspace packages running in parallel
- Heavy mocking throughout tests (500MB-1GB per worker)

---

## Examples

See [personalityMentionParser.test.ts](../../services/bot-client/src/utils/personalityMentionParser.test.ts) for a complete example demonstrating:

- Mocking dependencies
- Testing behavior vs implementation
- Edge case handling
- Clear test organization

---

## Best Practices

### ‚úÖ DO

- Write tests as you develop features
- Keep tests focused and independent
- Use descriptive test names
- Test edge cases and error conditions
- Mock all external dependencies
- Run tests before committing
- Fix flaky tests immediately

### ‚ùå DON'T

- Test implementation details
- Share state between tests
- Use real database/API calls
- Rely on test execution order
- Skip tests (fix or delete them)
- Test library code
- Write tests for trivial code

---

## Coverage Goals

**Current Status:**

- ‚úÖ `personalityMentionParser` - 100% coverage (example)
- ‚è≥ Core utilities - Expanding
- üöß Services - Future
- üöß Integration tests - Future

**Priorities:**

1. Critical path code (mention parsing, message handling)
2. Business logic (personality loading, memory retrieval)
3. Utilities (formatters, validators)
4. Less critical: Simple getters, type guards

**Target:** 70%+ coverage on critical paths, not 100% on everything

---

## Next Steps

1. **Add more utility tests** - Format helpers, validators
2. **Service layer tests** - PersonalityService, UserService
3. **Integration tests** - Full message flow
4. **E2E tests** - Discord ‚Üí AI response (future)

---

## Resources

- [Vitest Documentation](https://vitest.dev/)
- [Testing Best Practices](https://testingjavascript.com/)
- [Example: personalityMentionParser.test.ts](../../services/bot-client/src/utils/personalityMentionParser.test.ts)
